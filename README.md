# Web Scraping - Mercado Livre
Coletor e Analisador de Dados da Mercado Livre com Python, Selenium e Streamlit.

<br>

<!----------- ğŸ“ SumÃ¡rio ---------->
## ğŸ“ SumÃ¡rio
- [Projeto](#projeto)
- [Objetivo](#objetivo)
- [Principais Tecnologias](#principais-tecnologias)
- [Funcionalidades](#funcionalidades)
- [Funcionamento do Script de ExtraÃ§Ã£o](#funcionamento-do-script-de-extraÃ§Ã£o)
- [Como executar - Passo a Passo](#como-executar---passo-a-passo)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [Imagens do Projeto](#imagens-do-projeto)
- [Aprendizados](#aprendizados)
  
<br>

<!----------- ğŸ“Œ Projeto ---------->
## <a id="projeto">ğŸ“Œ Projeto</a>
Este projeto Ã© separado em 2 partes: 
  * Scrpit que extrai e limpa os dados dos produtos mais vendidos da Mercado Livre em categorias especÃ­ficas.
  * Interface visual que permite o usuÃ¡rio explorar os dados com Tabelas, EstatÃ­sticas e GrÃ¡ficos.

<br>

<!----------- ğŸ”“ Objetivo ---------->
## <a id="objetivo">ğŸ”“ Objetivo</a>
O objetivo deste projeto inicialmente era utilizar a API da Mercado Livre para acessar dados dos produtos mais vendidos e criar uma anÃ¡lise a partir disso, porÃ©m, particularmente tive dificuldades de acessar essa API por conta do aumento da seguranÃ§a do site. EntÃ£o, extraÃ­ os dados de maneira automatizada utilizando o conceito de Web Scraping (ExtraÃ§Ã£o de Dados) e os salvando em um Banco de Dados.

### â–¶ Qual problema ele resolve?
Este projeto resolve o problema de ExtraÃ§Ã£o de Dados via API, poupando tempo de ler e entender a documentaÃ§Ã£o, que as vezes para um iniciante, pode ser bem complexa.

### â–¶ Em qual contexto ele Ã© Ãºtil?
Ele Ã© Ãºtil para Engenhereiros de Dados na parte de extraÃ§Ã£o, podendo coletar os dados dos produtos facilmente e para Analistas de Dados, utilizando a interface visual para tirar insights valiosos sobre os produtos.

<br>

<!----------- ğŸ–¥ï¸ Principais Tecnologias ---------->
## <a id="principais-tecnologias">ğŸ–¥ï¸ Principais Tecnologias</a>
* **Python** - LÃ³gica principal do projeto.
* **Pandas** - Tratamento e AnÃ¡lise de dados.
* **Selenium** - AutomaÃ§Ã£o e Scraping.
* **SQLite** - Armazenamento local dos dados.
* **Streamlit** - Interface Web.

<br>

<!----------- â­ Funcionalidades ---------->
## <a id="funcionalidades">â­ Funcionalidades</a>
* âœ… Coleta de dados de forma automatizada.
* âœ… Armazenamento em um Banco de Dados.
* âœ… Dashboard interativo com estatÃ­sticas e grÃ¡ficos.
* âœ… Tabela dinÃ£mica e estilizada com filtros relacionais.
* âœ… OpÃ§Ã£o de Baixar os arquivos em formato CSV.

<br>

<!----------- ğŸ“„ Funcionamento do Script de ExtraÃ§Ã£o ---------->
## <a id="funcionamento-do-script-de-extraÃ§Ã£o">ğŸ“„ Funcionamento do Script de ExtraÃ§Ã£o</a>
Abaixo contÃ©m um fluxograma mostrando de maneira simples como o scrpit de extraÃ§Ã£o funciona.

<img width="700" height="700" alt="_Fluxograma" src="https://github.com/user-attachments/assets/553e48f3-985d-427b-ae88-b25c50fefea3" />

<br>

<!----------- âš™ï¸ Como Executar - Passo a Passo ---------->
## <a id="como-executar---passo-a-passo">âš™ï¸ Como Executar - Passo a Passo</a>
> Requisitos: **Python 3.10+**

```bash
# 1) Clonar o repositÃ³rio
git clone https://github.com/MathGeneze/Web-Scraping-Mercado-Livre.git
```
```bash
# 2) Instalar dependÃªncias
pip install -r requirements.txt
```
```bash
# 3) Executar o app
streamlit run navigation.py
```

<br>

<!----------- ğŸ—‚ï¸ Estrutura do Projeto ---------->
## <a id="estrutura-do-projeto">ğŸ—‚ï¸ Estrutura do Projeto</a>
Abaixo contÃ©m a estrutura do projeto:

```bash
ğŸ“¦ Estrutura
 â”£ ğŸ“‚ data                     # Dados e banco de dados local  
 â”ƒ â”— ğŸ—„ï¸ banco.db
 â”ƒ
 â”£ ğŸ“‚ fonts                    # Arquivos de referÃªncia / documentaÃ§Ã£o por tecnologia*
 â”£ ğŸ“‚ pages                    # PÃ¡ginas da aplicaÃ§Ã£o Streamlit
 â”ƒ â”£ ğŸ main.py                # PÃ¡gina principal (Home)
 â”ƒ â”£ ğŸ visao_geral.py         # VisÃ£o geral dos dados
 â”ƒ â”— ğŸ web_scraping.py        # PÃ¡gina explicando o scraping
 â”ƒ
 â”£ ğŸ“‚ src                      # CÃ³digo-fonte principal
 â”ƒ â”£ ğŸ“‚ extracao               # MÃ³dulo de extraÃ§Ã£o de dados
 â”ƒ â”ƒ â”— ğŸ extracao_dados.py
 â”ƒ â”ƒ
 â”ƒ â”— ğŸ“‚ metricas               # CÃ¡lculo e anÃ¡lise de mÃ©tricas
 â”ƒ   â”— ğŸ estatisticas.py
 â”ƒ
 â”£ ğŸ“‚ style                    # Estilos visuais da aplicaÃ§Ã£o
 â”ƒ â”£ ğŸ“‚ icons
 â”ƒ â”£ ğŸ“‚ image
 â”ƒ â”£ ğŸ“‚ videos
 â”ƒ â”£ ğŸ¨ style.css
 â”ƒ â”£ ğŸ¨ style2.css
 â”ƒ â”— ğŸ¨ style3.css
 â”ƒ
 â”— ğŸ“˜ README.md
```

<br>

<!----------- ğŸ“¸ Imagens do Projeto ---------->
## <a id="imagens-do-projeto">ğŸ“¸ Imagens do Projeto</a>
### 1ï¸âƒ£ Home: PÃ¡gina inicial + Tabela com produtos
<img width="550" height="550" alt="image" src="https://github.com/user-attachments/assets/539f8365-79d7-47fe-a01e-6e21bc7c8407" />

### 2ï¸âƒ£ Home: Fitros da Tabela
<img width="550" height="550" alt="image" src="https://github.com/user-attachments/assets/f8b0dd7b-6e7d-4f99-8d6c-fb28f0df4dcf" />

### 3ï¸âƒ£ Home: VisualizaÃ§Ã£o Ãºnica dos produtos extraÃ­dos
<img width="550" height="550" alt="image" src="https://github.com/user-attachments/assets/8b4bb47c-a77e-4c83-ba94-e22dca83682f" />

### 4ï¸âƒ£ Home: EstatÃ­sticas dos produtos 
<img width="550" height="550" alt="image" src="https://github.com/user-attachments/assets/52ae2f7e-aaca-4cc3-9a70-8e44a3d116db" />

### 5ï¸âƒ£ Home: GrÃ¡fico DinÃ¢mico 
<img width="550" height="550" alt="image" src="https://github.com/user-attachments/assets/71a71fef-3cc0-4747-8340-3c1fc0a47d8c" />

### 6ï¸âƒ£ VisÃ£o Geral: ExplicaÃ§Ã£o do projeto
<img width="550" height="550" alt="image" src="https://github.com/user-attachments/assets/a1ff3140-7e4d-4155-9e3c-e48d1fc41552" />

### 7ï¸âƒ£ ExtraÃ§Ã£o de Dados: ExplicaÃ§Ã£o do script de extraÃ§Ã£o
<img width="550" height="550" alt="image" src="https://github.com/user-attachments/assets/2e72932c-b8b2-4cf8-a0c8-8f7314a03d87" />

<br>

<!----------- ğŸ’¡ Aprendizados ---------->
## <a id="aprendizados">ğŸ’¡ Aprendizados</a>
Este projeto foi extremamente relevante para mim. AlÃ©m de aprender sobre extraÃ§Ã£o de dados, ainda reforcei meus conhecimentos em SQL e salvei os dados em um banco de dados (no comeÃ§o do projeto, eles eram salvos em arquivos csv). TambÃ©m aprendi a importÃ¢ncia de planejar a Estrutura de um Projeto, pois ao longo deste espeficadamente, as pÃ¡ginas do site foram surgindo ao longo do tempo sem planejamento. 



